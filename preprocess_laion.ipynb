{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ec3b6d2c-6e62-426a-bd09-1c36915adbf6",
   "metadata": {},
   "source": [
    "# Preprocess the laion-art dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a56f7c-7d49-4743-b1c5-d4c55cd393e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_name = \"laion/laion-art\"\n",
    "dataset = load_dataset(\n",
    "            dataset_name,\n",
    "            None,\n",
    "            None,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03749b98-678d-4028-87fd-0c5ea28a4816",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_dataset = dataset['train'].filter(lambda example: example['LANGUAGE'] in ['en', 'nolang'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7c3281-7af0-4b96-befd-c6148110247e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def print_arr(arr):\n",
    "    print(np.mean(arr), np.min(arr), np.max(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8450f6-1e87-4254-a565-e1b15c477b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "ids = random.sample(range(len(en_dataset)), 10000)\n",
    "small_en_dataset = en_dataset.select(ids)\n",
    "small_en_dataset = small_en_dataset.train_test_split(test_size=0.1)\n",
    "small_en_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934c5c78-bc33-4413-b073-7033c6c1bcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_arr(small_en_dataset['train']['aesthetic'])\n",
    "print_arr(en_dataset['aesthetic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a358dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate code to download the images from url with multi-processing\n",
    "import requests\n",
    "from PIL import Image\n",
    "import io\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "\n",
    "def download_image(url, im_path):\n",
    "    try:\n",
    "        response = requests.get(url).content\n",
    "        im = Image.open(io.BytesIO(response))\n",
    "        im.save(im_path)\n",
    "    except Exception as e:\n",
    "        print(f'Failed to save {im_path} due to {e}')\n",
    "\n",
    "def download_images(split, sub_dataset):\n",
    "    sub_im_dir = os.path.join(im_dir, split)\n",
    "    os.makedirs(sub_im_dir, exist_ok=True)\n",
    "    cvs_filename = os.path.join(sub_im_dir, \"metadata.csv\")\n",
    "    with open(cvs_filename, 'w') as csvfile:\n",
    "        # creating a csv writer object \n",
    "        csvwriter = csv.writer(csvfile)    \n",
    "        # writing the fields\n",
    "        # csvwriter.writerow(['file_name', 'text', 'aesthetic'])\n",
    "        for im_id, example in tqdm(enumerate(sub_dataset)):\n",
    "            im_path = os.path.join(sub_im_dir, f'{im_id}.png')\n",
    "            if os.path.isfile(im_path):\n",
    "                continue\n",
    "            try:\n",
    "                url, text, aesthetic = example['URL'], example['TEXT'], example['aesthetic']\n",
    "                download_image(url, im_path)\n",
    "                csvwriter.writerow([f'{im_id}.png', text, aesthetic])\n",
    "            except Exception as e:\n",
    "                print(f'Failed to save {im_path} due to {e}')\n",
    "\n",
    "def download_images_mp(split, sub_dataset):\n",
    "    sub_im_dir = os.path.join(im_dir, split)\n",
    "    os.makedirs(sub_im_dir, exist_ok=True)\n",
    "    cvs_filename = os.path.join(sub_im_dir, \"metadata.csv\")\n",
    "    with open(cvs_filename, 'w') as csvfile:\n",
    "        # creating a csv writer object \n",
    "        csvwriter = csv.writer(csvfile)    \n",
    "        # writing the fields\n",
    "        csvwriter.writerow(['file_name', 'text', 'aesthetic'])\n",
    "        with multiprocessing.Pool(8) as p:\n",
    "            for im_id, example in tqdm(enumerate(sub_dataset)):\n",
    "                im_path = os.path.join(sub_im_dir, f'{im_id}.png')\n",
    "                if os.path.isfile(im_path):\n",
    "                    continue\n",
    "                try:\n",
    "                    url, text, aesthetic = example['URL'], example['TEXT'], example['aesthetic']\n",
    "                    p.apply_async(download_image, args=(url, im_path))\n",
    "                    csvwriter.writerow([f'{im_id}.png', text, aesthetic])\n",
    "                except Exception as e:\n",
    "                    print(f'Failed to save {im_path} due to {e}')\n",
    "            p.close()\n",
    "            p.join()\n",
    "\n",
    "im_dir = \"data/laion-art\"\n",
    "os.makedirs(im_dir, exist_ok=True)\n",
    "# download_images_mp('train', small_en_dataset['train'])\n",
    "download_images_mp('test', small_en_dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40da3699",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "im_dir = \"data/laion-art\"\n",
    "sub_im_dir = os.path.join(im_dir, \"train\")\n",
    "cvs_filename = os.path.join(sub_im_dir, \"metadata.csv\")\n",
    "\n",
    "import pandas as pd\n",
    "  \n",
    "# reading the csv file\n",
    "df = pd.read_csv(cvs_filename)\n",
    "  \n",
    "# updating the column value/data\n",
    "# removeing the prefix from the file_name\n",
    "\n",
    "df['file_name'] = df['file_name'].apply(lambda s: s[21:])\n",
    "  \n",
    "# writing into the file\n",
    "df.to_csv(cvs_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66274d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import csv\n",
    "\n",
    "im_dir = \"data/laion-art/train\"\n",
    "\n",
    "csv_filename = os.path.join(im_dir, \"metadata.csv\")\n",
    "available_im_paths = set()\n",
    "with open(csv_filename, 'r') as csvfile:\n",
    "    csvreader = csv.reader(csvfile)\n",
    "    for im_path, text, aesthetic in csvreader:\n",
    "        available_im_paths.add(os.path.join(im_dir, im_path))\n",
    "print(list(available_im_paths)[:10])\n",
    "print(len(available_im_paths))\n",
    "im_paths = glob(os.path.join(im_dir, \"*.png\"))\n",
    "print(im_paths[:10])\n",
    "for im_path in im_paths:\n",
    "    if im_path not in available_im_paths:\n",
    "        print(im_path)\n",
    "        os.remove(im_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9784ed90",
   "metadata": {},
   "source": [
    "# Upload dataset to hugging face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ce8b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from huggingface_hub import create_repo\n",
    "\n",
    "dataset = load_dataset(\"data/laion-art\")\n",
    "repo_id = create_repo(\n",
    "                repo_id=\"fantasyfish/laion-art\", exist_ok=True, token=\"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\"\n",
    "            ).repo_id\n",
    "dataset.push_to_hub(\"fantasyfish/laion-art\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
